{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca4349cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Device:\", torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a28b1e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import albumentations as A\n",
    "import timm\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "from torch.cuda.amp import autocast, GradScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f071875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset for Cloud Detection\n",
    "class CloudDataset(Dataset):\n",
    "    def __init__(self, metadata, root_dir, transform=None):\n",
    "        self.metadata = metadata\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.feature_dir = os.path.join(root_dir, 'train_features')\n",
    "        self.label_dir = os.path.join(root_dir, 'train_labels')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.metadata)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        chip_id = self.metadata.iloc[idx]['chip_id']\n",
    "        feature_path = os.path.join(self.feature_dir, chip_id)\n",
    "        label_path = os.path.join(self.label_dir, f\"{chip_id}.tif\")\n",
    "\n",
    "        bands = ['B02', 'B03', 'B04', 'B08']\n",
    "        features = []\n",
    "\n",
    "        for band in bands:\n",
    "            with rasterio.open(os.path.join(feature_path, f'{band}.tif')) as src:\n",
    "                features.append(src.read(1).astype(np.float32))\n",
    "\n",
    "        image = np.stack(features, axis=-1)  # [H, W, 4]\n",
    "\n",
    "        with rasterio.open(label_path) as src:\n",
    "            mask = src.read(1).astype(np.float32)  # [H, W]\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image, mask=mask)\n",
    "            image = augmented['image']\n",
    "            mask = augmented['mask']\n",
    "\n",
    "        image = torch.from_numpy(image).permute(2, 0, 1).float()  # [4, H, W]\n",
    "        mask = torch.from_numpy(mask).unsqueeze(0).float()                  # [H, W]\n",
    "\n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfa587ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation\n",
    "mean_vals = (0.5, 0.5, 0.5, 0.5)\n",
    "std_vals = (0.5, 0.5, 0.5, 0.5)\n",
    "\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(256, 256),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.RandomRotate90(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "    A.Normalize(mean=mean_vals, std=std_vals, max_pixel_value=65535.0),\n",
    "], additional_targets={'mask': 'mask'})\n",
    "\n",
    "val_transform = A.Compose([\n",
    "    A.Resize(256, 256),\n",
    "    A.Normalize(mean=mean_vals, std=std_vals, max_pixel_value=65535.0),\n",
    "], additional_targets={'mask': 'mask'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4eb9f7d-258a-4765-b01f-30547789b0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and Split Dataset\n",
    "root_dir = 'data'\n",
    "metadata = pd.read_csv('data/train_metadata.csv')\n",
    "\n",
    "train_meta, temp_meta = train_test_split(metadata, test_size=0.3, random_state=42)\n",
    "val_meta, test_meta = train_test_split(temp_meta, test_size=2/3, random_state=42)\n",
    "\n",
    "train_dataset = CloudDataset(train_meta, root_dir, transform=train_transform)\n",
    "val_dataset = CloudDataset(val_meta, root_dir, transform=val_transform)\n",
    "test_dataset = CloudDataset(test_meta, root_dir, transform=val_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=4)\n",
    "\n",
    "print(\"Train samples:\", len(train_dataset))\n",
    "print(\"Val samples:\", len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "666f672d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lightweight Xception Backbone with 4-channel input\n",
    "class XceptionBackbone(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(XceptionBackbone, self).__init__()\n",
    "        self.model = timm.create_model('xception41', pretrained=True, features_only=True, in_chans=4)\n",
    "        self.pool1 = nn.AvgPool2d(2, stride=2)\n",
    "        self.pool2 = nn.AvgPool2d(2, stride=2)\n",
    "        self.pool3 = nn.AvgPool2d(2, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.model(x)\n",
    "        low_level = features[1]\n",
    "        out = features[3]\n",
    "        out = self.pool1(out)\n",
    "        out = self.pool2(out)\n",
    "        out = self.pool3(out)\n",
    "        return {'out': out, 'low_level': low_level}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f872af50-9e84-486b-8f34-dc318999f6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ASPP\n",
    "class ASPP(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ASPP, self).__init__()\n",
    "        self.aspp1 = nn.Sequential(nn.Conv2d(in_channels, out_channels, 3, padding=1, dilation=1, bias=False),\n",
    "                                   nn.BatchNorm2d(out_channels), nn.ReLU())\n",
    "        self.aspp2 = nn.Sequential(nn.Conv2d(in_channels, out_channels, 3, padding=3, dilation=3, bias=False),\n",
    "                                   nn.BatchNorm2d(out_channels), nn.ReLU())\n",
    "        self.aspp3 = nn.Sequential(nn.Conv2d(in_channels, out_channels, 3, padding=9, dilation=9, bias=False),\n",
    "                                   nn.BatchNorm2d(out_channels), nn.ReLU())\n",
    "        self.aspp4 = nn.Sequential(nn.Conv2d(in_channels, out_channels, 3, padding=12, dilation=12, bias=False),\n",
    "                                   nn.BatchNorm2d(out_channels), nn.ReLU())\n",
    "        self.global_avg_pool = nn.Sequential(nn.AdaptiveAvgPool2d((1, 1)),\n",
    "                                             nn.Conv2d(in_channels, out_channels, 1, bias=False),\n",
    "                                             nn.BatchNorm2d(out_channels), nn.ReLU())\n",
    "        self.conv1 = nn.Conv2d(out_channels * 5, out_channels, 1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.aspp1(x)\n",
    "        x2 = self.aspp2(x)\n",
    "        x3 = self.aspp3(x)\n",
    "        x4 = self.aspp4(x)\n",
    "        x5 = self.global_avg_pool(x)\n",
    "        x5 = F.interpolate(x5, size=x4.size()[2:], mode='bilinear', align_corners=False)\n",
    "        x = torch.cat((x1, x2, x3, x4, x5), dim=1)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        return self.relu(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32b99df5-f59d-4d2b-9f64-9e44f5410866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CBAM\n",
    "class ImprovedCBAM(nn.Module):\n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super(ImprovedCBAM, self).__init__()\n",
    "        self.channel_attention = nn.Sequential(nn.AdaptiveAvgPool2d(1),\n",
    "                                               nn.Conv2d(channels, channels // reduction, 1),\n",
    "                                               nn.ReLU(),\n",
    "                                               nn.Conv2d(channels // reduction, channels, 1),\n",
    "                                               nn.Sigmoid())\n",
    "        self.spatial_attention = nn.Sequential(nn.Conv2d(2, 1, 7, padding=3), nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        ca = self.channel_attention(x)\n",
    "        x = x * ca + x\n",
    "        sa = torch.cat([torch.max(x, 1, keepdim=True)[0], torch.mean(x, 1, keepdim=True)], dim=1)\n",
    "        sa = self.spatial_attention(sa)\n",
    "        return x * sa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "485a16d8-3359-41ca-8532-957fcff3d997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAU\n",
    "class GAU(nn.Module):\n",
    "    def __init__(self, low_channels, high_channels):\n",
    "        super(GAU, self).__init__()\n",
    "        self.conv_low = nn.Conv2d(low_channels, 256, 3, padding=1, bias=False)\n",
    "        self.bn_low = nn.BatchNorm2d(256)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.conv_weight = nn.Conv2d(high_channels, 256, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, low_features, high_features):\n",
    "        low = self.conv_low(low_features)\n",
    "        low = self.bn_low(low)\n",
    "        low = self.relu(low)\n",
    "        high = F.interpolate(high_features, size=low.size()[2:], mode='bilinear', align_corners=False)\n",
    "        weights = self.global_pool(high_features)\n",
    "        weights = self.conv_weight(weights)\n",
    "        weights = self.sigmoid(weights)\n",
    "        low = low * weights\n",
    "        return low + high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "259c3b40-3b03-44ae-9504-9b75f0916399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Model\n",
    "class ImprovedDeepLabV3Plus(nn.Module):\n",
    "    def __init__(self, num_classes=1):\n",
    "        super(ImprovedDeepLabV3Plus, self).__init__()\n",
    "        self.backbone = XceptionBackbone()\n",
    "        self.aspp = ASPP(in_channels=1024, out_channels=256)\n",
    "        self.cbam = ImprovedCBAM(256)\n",
    "        self.gau = GAU(low_channels=256, high_channels=256)\n",
    "        self.final_conv = nn.Conv2d(256, num_classes, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        input_shape = x.shape[-2:]\n",
    "        features = self.backbone(x)\n",
    "        low_level = features['low_level']\n",
    "        x = features['out']\n",
    "        x = self.aspp(x)\n",
    "        x = self.cbam(x)\n",
    "        x = self.gau(low_level, x)\n",
    "        x = F.interpolate(x, size=input_shape, mode='bilinear', align_corners=False)\n",
    "        return torch.sigmoid(self.final_conv(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f2cea22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dice Loss\n",
    "class DiceLoss(nn.Module):\n",
    "    def forward(self, pred, target):\n",
    "        smooth = 1.\n",
    "        pred = pred.view(-1)\n",
    "        target = target.view(-1)\n",
    "        intersection = (pred * target).sum()\n",
    "        return 1 - (2.*intersection + smooth)/(pred.sum()+target.sum()+smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd74fbc1-66a4-4c53-9790-26745de49646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics\n",
    "def compute_metrics(pred, target, threshold=0.5):\n",
    "    pred = (pred > threshold).float()\n",
    "    TP = (pred * target).sum()\n",
    "    TN = ((1 - pred) * (1 - target)).sum()\n",
    "    FP = (pred * (1 - target)).sum()\n",
    "    FN = ((1 - pred) * target).sum()\n",
    "\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN + 1e-6)\n",
    "    precision = TP / (TP + FP + 1e-6)\n",
    "    recall = TP / (TP + FN + 1e-6)\n",
    "    iou = TP / (TP + FP + FN + 1e-6)\n",
    "\n",
    "    return accuracy.item(), precision.item(), recall.item(), iou.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1dc6fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training with Mixed Precision and Validation Fix\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=25, patience=10):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    with open('training_results.csv', 'w', newline='') as csvfile:\n",
    "        fieldnames = ['epoch', 'train_loss', 'val_loss', 'accuracy', 'precision', 'recall', 'iou', 'learning_rate']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            train_loss = 0.0\n",
    "            total_accuracy = 0.0\n",
    "            total_precision = 0.0\n",
    "            total_recall = 0.0\n",
    "            total_iou = 0.0\n",
    "\n",
    "            progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}', unit='batch')\n",
    "\n",
    "            for images, masks in progress_bar:\n",
    "                images, masks = images.to(device), masks.to(device)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with autocast():\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, masks)\n",
    "                \n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "\n",
    "                accuracy, precision, recall, iou = compute_metrics(outputs, masks)\n",
    "                total_accuracy += accuracy\n",
    "                total_precision += precision\n",
    "                total_recall += recall\n",
    "                total_iou += iou\n",
    "\n",
    "                progress_bar.set_postfix({\n",
    "                    'loss': f'{loss.item():.4f}',\n",
    "                    'accuracy': f'{accuracy:.4f}',\n",
    "                    'precision': f'{precision:.4f}',\n",
    "                    'recall': f'{recall:.4f}',\n",
    "                    'IoU': f'{iou:.4f}'\n",
    "                })\n",
    "\n",
    "            # Validation loss\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            with torch.no_grad():\n",
    "                for images, masks in val_loader:\n",
    "                    images, masks = images.to(device), masks.to(device)\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, masks)\n",
    "                    val_loss += loss.item()\n",
    "\n",
    "            avg_train_loss = train_loss / len(train_loader)\n",
    "            avg_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "            avg_accuracy = total_accuracy / len(train_loader)\n",
    "            avg_precision = total_precision / len(train_loader)\n",
    "            avg_recall = total_recall / len(train_loader)\n",
    "            avg_iou = total_iou / len(train_loader)\n",
    "\n",
    "            writer.writerow({\n",
    "                'epoch': epoch + 1,\n",
    "                'train_loss': avg_train_loss,\n",
    "                'val_loss': avg_val_loss,\n",
    "                'accuracy': avg_accuracy,\n",
    "                'precision': avg_precision,\n",
    "                'recall': avg_recall,\n",
    "                'iou': avg_iou,\n",
    "                'learning_rate': optimizer.param_groups[0]['lr']\n",
    "            })\n",
    "            csvfile.flush()\n",
    "\n",
    "            scheduler.step()\n",
    "\n",
    "            if avg_val_loss < best_val_loss:\n",
    "                best_val_loss = avg_val_loss\n",
    "                epochs_no_improve = 0\n",
    "                torch.save(model.state_dict(), 'final1_model.pth')\n",
    "            else:\n",
    "                epochs_no_improve += 1\n",
    "                if epochs_no_improve >= patience:\n",
    "                    print(f\"Early stopping triggered at epoch {epoch + 1}\")\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc5f95b-dfb2-4b21-9d5a-a1935f20f15e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pinga\\AppData\\Local\\Temp\\ipykernel_22488\\1125508918.py:5: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "Epoch 1/15:   0%|                                                                          | 0/1028 [00:00<?, ?batch/s]"
     ]
    }
   ],
   "source": [
    "# Main\n",
    "if __name__ == \"__main__\":\n",
    "    model = ImprovedDeepLabV3Plus(num_classes=1)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50)\n",
    "    # Use BCEWithLogitsLoss for stability with mixed precision\n",
    "    criterion = lambda pred, target: 0.5 * nn.BCEWithLogitsLoss()(pred, target) + 0.5 * DiceLoss()(pred, target)\n",
    "    train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=15, patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d2fb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Reuse compute_metrics and model definition\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load model\n",
    "model = ImprovedDeepLabV3Plus(num_classes=1)\n",
    "model.load_state_dict(torch.load('final1_model.pth', map_location=device))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Metrics accumulators\n",
    "total_accuracy = 0.0\n",
    "total_precision = 0.0\n",
    "total_recall = 0.0\n",
    "total_iou = 0.0\n",
    "num_batches = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, masks in tqdm(test_loader, desc=\"Evaluating on Test Set\"):\n",
    "        images, masks = images.to(device), masks.to(device)\n",
    "        outputs = model(images)\n",
    "\n",
    "        accuracy, precision, recall, iou = compute_metrics(outputs, masks)\n",
    "        total_accuracy += accuracy\n",
    "        total_precision += precision\n",
    "        total_recall += recall\n",
    "        total_iou += iou\n",
    "        num_batches += 1\n",
    "\n",
    "# Average metrics over all test batches\n",
    "avg_accuracy = total_accuracy / num_batches\n",
    "avg_precision = total_precision / num_batches\n",
    "avg_recall = total_recall / num_batches\n",
    "avg_iou = total_iou / num_batches\n",
    "\n",
    "print(\"\\n✅ Final Evaluation on Test Set:\")\n",
    "print(f\"Accuracy:  {avg_accuracy:.4f}\")\n",
    "print(f\"Precision: {avg_precision:.4f}\")\n",
    "print(f\"Recall:    {avg_recall:.4f}\")\n",
    "print(f\"IoU:       {avg_iou:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e621573f-ec23-4f04-9ce4-9a466cb5b8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "metrics = {\n",
    "    \"Accuracy\": [avg_accuracy],\n",
    "    \"Precision\": [avg_precision],\n",
    "    \"Recall\": [avg_recall],\n",
    "    \"IoU\": [avg_iou]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(metrics)\n",
    "df.to_csv(\"test_metrics.csv\", index=False)\n",
    "\n",
    "print(\"✅ Test set metrics saved to: test_metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5def2f-7c28-40c8-ae16-fa6d25f50fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Load the training results CSV file\n",
    "training_results = pd.read_csv('training_results.csv')\n",
    "\n",
    "# Load the model (replace with your actual model class)\n",
    "model_path = 'final1_model.pth'  # Path to the saved best model\n",
    "model = ImprovedDeepLabV3Plus(num_classes=1)  # Use the same model class you used during training\n",
    "# Load the model with weights_only=True to avoid potential security risks\n",
    "model.load_state_dict(torch.load('final1_model.pth', weights_only=True))\n",
    "\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Plot Loss (Training vs Validation) and save\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(training_results['epoch'], training_results['train_loss'], label='Train Loss', color='blue')\n",
    "plt.plot(training_results['epoch'], training_results['val_loss'], label='Validation Loss', color='red')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training vs Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()  # Display the plot\n",
    "plt.close()\n",
    "\n",
    "# Plot Accuracy, Precision, Recall, IoU over epochs and save\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(training_results['epoch'], training_results['accuracy'], label='Accuracy', color='green')\n",
    "plt.plot(training_results['epoch'], training_results['precision'], label='Precision', color='purple')\n",
    "plt.plot(training_results['epoch'], training_results['recall'], label='Recall', color='orange')\n",
    "plt.plot(training_results['epoch'], training_results['iou'], label='IoU', color='brown')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Metrics')\n",
    "plt.title('Training Metrics (Accuracy, Precision, Recall, IoU)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()  # Display the plot\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
