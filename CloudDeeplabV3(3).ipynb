{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46faaab6-bc0c-4857-b263-959ec17ad6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Device:\", torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f1cc048-f721-491a-9728-ccd956699b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import albumentations as A\n",
    "import timm\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "from torch.cuda.amp import autocast, GradScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ed89014-fcb2-46d2-85f9-101a9c67bbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CloudDataset(Dataset):\n",
    "    def __init__(self, metadata, root_dir, transform=None):\n",
    "        self.metadata = metadata\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.feature_dir = os.path.join(root_dir, 'train_features')\n",
    "        self.label_dir = os.path.join(root_dir, 'train_labels')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.metadata)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        chip_id = self.metadata.iloc[idx]['chip_id']\n",
    "        feature_path = os.path.join(self.feature_dir, chip_id)\n",
    "        label_path = os.path.join(self.label_dir, f\"{chip_id}.tif\")\n",
    "\n",
    "        bands = ['B02', 'B03', 'B04', 'B08']\n",
    "        features = []\n",
    "\n",
    "        for band in bands:\n",
    "            with rasterio.open(os.path.join(feature_path, f'{band}.tif')) as src:\n",
    "                features.append(src.read(1).astype(np.float32))\n",
    "\n",
    "        image = np.stack(features, axis=-1)\n",
    "\n",
    "        with rasterio.open(label_path) as src:\n",
    "            mask = src.read(1).astype(np.float32)\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image, mask=mask)\n",
    "            image = augmented['image']\n",
    "            mask = augmented['mask']\n",
    "\n",
    "        image = torch.from_numpy(image).permute(2, 0, 1).float()\n",
    "        mask = torch.from_numpy(mask).unsqueeze(0).float()\n",
    "\n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fc66fb3-55db-47d4-8157-3a455caafeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_vals = (0.5, 0.5, 0.5, 0.5)\n",
    "std_vals = (0.5, 0.5, 0.5, 0.5)\n",
    "\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(256, 256),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.RandomRotate90(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "    A.Normalize(mean=mean_vals, std=std_vals, max_pixel_value=65535.0),\n",
    "], additional_targets={'mask': 'mask'})\n",
    "\n",
    "val_transform = A.Compose([\n",
    "    A.Resize(256, 256),\n",
    "    A.Normalize(mean=mean_vals, std=std_vals, max_pixel_value=65535.0),\n",
    "], additional_targets={'mask': 'mask'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f950fb27-5747-439f-8062-029e7b99c322",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = 'data'\n",
    "metadata = pd.read_csv('data/train_metadata.csv')\n",
    "\n",
    "train_meta, temp_meta = train_test_split(metadata, test_size=0.3, random_state=42)\n",
    "val_meta, test_meta = train_test_split(temp_meta, test_size=2/3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2e2474e-13ff-4b93-91bc-1660db060b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 8223\n",
      "Val samples: 1175\n"
     ]
    }
   ],
   "source": [
    "train_dataset = CloudDataset(train_meta, root_dir, train_transform)\n",
    "val_dataset   = CloudDataset(val_meta, root_dir, val_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=0)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=0)\n",
    "\n",
    "print(\"Train samples:\", len(train_dataset))\n",
    "print(\"Val samples:\", len(val_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2e3c509-ef18-4968-b96e-5a4c2be50961",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XceptionBackbone(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(\n",
    "            'xception41', pretrained=True, features_only=True, in_chans=4\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.model(x)\n",
    "        return features[1], features[3]\n",
    "class ASPP(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "class ImprovedDeepLabV3Plus(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.backbone = XceptionBackbone()\n",
    "        self.aspp = ASPP(1024, 256)\n",
    "        self.final = nn.Conv2d(256, 1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h, w = x.shape[-2:]\n",
    "        low, high = self.backbone(x)\n",
    "        x = self.aspp(high)\n",
    "        x = F.interpolate(x, size=(h, w), mode='bilinear', align_corners=False)\n",
    "        return torch.sigmoid(self.final(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d7045db-3592-4a00-8d55-1436d08dad03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    def forward(self, pred, target):\n",
    "        smooth = 1.\n",
    "        pred = pred.view(-1)\n",
    "        target = target.view(-1)\n",
    "        intersection = (pred * target).sum()\n",
    "        return 1 - (2.*intersection + smooth)/(pred.sum()+target.sum()+smooth)\n",
    "def compute_iou(pred, target):\n",
    "    pred = (pred > 0.5).float()\n",
    "    intersection = (pred * target).sum()\n",
    "    union = pred.sum() + target.sum() - intersection\n",
    "    return (intersection / (union + 1e-6)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eab6a29f-8d8e-4194-890d-06b002baa82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred, target, threshold=0.5):\n",
    "    pred = (pred > threshold).float()\n",
    "\n",
    "    TP = (pred * target).sum()\n",
    "    TN = ((1 - pred) * (1 - target)).sum()\n",
    "    FP = (pred * (1 - target)).sum()\n",
    "    FN = ((1 - pred) * target).sum()\n",
    "\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN + 1e-6)\n",
    "    precision = TP / (TP + FP + 1e-6)\n",
    "    recall = TP / (TP + FN + 1e-6)\n",
    "    iou = TP / (TP + FP + FN + 1e-6)\n",
    "\n",
    "    return accuracy.item(), precision.item(), recall.item(), iou.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd93a794-d4d1-4719-9dbb-6d6e68c81752",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.amp import autocast, GradScaler\n",
    "import csv\n",
    "\n",
    "def train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    num_epochs=35,\n",
    "    patience=35\n",
    "):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50)\n",
    "\n",
    "    # ✅ AMP-SAFE LOSS\n",
    "    bce_loss = nn.BCEWithLogitsLoss()\n",
    "    criterion = lambda p, t: (\n",
    "        0.5 * bce_loss(p, t) +\n",
    "        0.5 * DiceLoss()(torch.sigmoid(p), t)\n",
    "    )\n",
    "\n",
    "    scaler = GradScaler(\"cuda\")\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    with open(\"training_results3.csv\", \"w\", newline=\"\") as f:\n",
    "        writer = csv.DictWriter(\n",
    "            f,\n",
    "            fieldnames=[\n",
    "                \"epoch\", \"train_loss\", \"val_loss\",\n",
    "                \"accuracy\", \"precision\", \"recall\", \"iou\"\n",
    "            ]\n",
    "        )\n",
    "        writer.writeheader()\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            # ---------- TRAIN ----------\n",
    "            model.train()\n",
    "            train_loss = 0.0\n",
    "            acc = prec = rec = iou = 0.0\n",
    "\n",
    "            for imgs, masks in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "                imgs, masks = imgs.to(device), masks.to(device)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with autocast(device_type=\"cuda\"):\n",
    "                    preds = model(imgs)          # logits\n",
    "                    loss = criterion(preds, masks)\n",
    "\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "\n",
    "                # Metrics use probabilities\n",
    "                probs = torch.sigmoid(preds)\n",
    "                a, p, r, i = compute_metrics(probs, masks)\n",
    "                acc += a; prec += p; rec += r; iou += i\n",
    "\n",
    "            train_loss /= len(train_loader)\n",
    "            acc /= len(train_loader)\n",
    "            prec /= len(train_loader)\n",
    "            rec /= len(train_loader)\n",
    "            iou /= len(train_loader)\n",
    "\n",
    "            # ---------- VALIDATION ----------\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            with torch.no_grad():\n",
    "                for imgs, masks in val_loader:\n",
    "                    imgs, masks = imgs.to(device), masks.to(device)\n",
    "                    preds = model(imgs)\n",
    "                    val_loss += criterion(preds, masks).item()\n",
    "\n",
    "            val_loss /= len(val_loader)\n",
    "\n",
    "            writer.writerow({\n",
    "                \"epoch\": epoch + 1,\n",
    "                \"train_loss\": train_loss,\n",
    "                \"val_loss\": val_loss,\n",
    "                \"accuracy\": acc,\n",
    "                \"precision\": prec,\n",
    "                \"recall\": rec,\n",
    "                \"iou\": iou\n",
    "            })\n",
    "            f.flush()\n",
    "\n",
    "            scheduler.step()\n",
    "\n",
    "            print(\n",
    "                f\"Epoch {epoch+1}: \"\n",
    "                f\"Train={train_loss:.4f}, Val={val_loss:.4f}, IoU={iou:.4f}\"\n",
    "            )\n",
    "\n",
    "            # ---------- EARLY STOPPING ----------\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                epochs_no_improve = 0\n",
    "                torch.save(model.state_dict(), \"final1_model3.pth\")\n",
    "            else:\n",
    "                epochs_no_improve += 1\n",
    "                if epochs_no_improve >= patience:\n",
    "                    print(\"⛔ Early stopping triggered\")\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9859caef-78be-4a37-b2c5-0b721d729c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/35: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 1028/1028 [07:23<00:00,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train=0.4388, Val=0.4082, IoU=0.6790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/35: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 1028/1028 [07:44<00:00,  2.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train=0.4288, Val=0.4050, IoU=0.7220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/35: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 1028/1028 [07:33<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train=0.4285, Val=0.4115, IoU=0.7463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/35: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 1028/1028 [07:28<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train=0.4258, Val=0.4046, IoU=0.7649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/35:  22%|█████████████████████▎                                                                         | 231/1028 [01:42<06:00,  2.21it/s]"
     ]
    }
   ],
   "source": [
    "model = ImprovedDeepLabV3Plus()\n",
    "train_model(model, train_loader, val_loader, num_epochs=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea6bfb3-f369-44a5-be53-f210de76507e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"training_results3.csv\")\n",
    "\n",
    "# ---------- LOSS PLOT ----------\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(df[\"epoch\"], df[\"train_loss\"], label=\"Train Loss\")\n",
    "plt.plot(df[\"epoch\"], df[\"val_loss\"], label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training vs Validation Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# ---------- METRICS PLOT ----------\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(df[\"epoch\"], df[\"accuracy\"], label=\"Accuracy\")\n",
    "plt.plot(df[\"epoch\"], df[\"precision\"], label=\"Precision\")\n",
    "plt.plot(df[\"epoch\"], df[\"recall\"], label=\"Recall\")\n",
    "plt.plot(df[\"epoch\"], df[\"iou\"], label=\"IoU\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"Segmentation Metrics vs Epoch\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c09485-4342-49b9-b435-e623544c507c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "num_images = 3\n",
    "indices = random.sample(range(len(val_dataset)), num_images)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for idx in indices:\n",
    "        image, mask = val_dataset[idx]\n",
    "\n",
    "        image = image.unsqueeze(0).to(device)\n",
    "        mask = mask.unsqueeze(0).to(device)\n",
    "\n",
    "        output = model(image)\n",
    "        pred = (output > 0.5).float()\n",
    "\n",
    "        img = image[0].cpu().numpy()\n",
    "        gt = mask[0][0].cpu().numpy()\n",
    "        pr = pred[0][0].cpu().numpy()\n",
    "\n",
    "        img = (img - img.min()) / (img.max() - img.min() + 1e-8)\n",
    "        rgb = img[[2, 1, 0], :, :].transpose(1, 2, 0)\n",
    "\n",
    "        fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "        axs[0].imshow(rgb)\n",
    "        axs[0].set_title(\"RGB Image\")\n",
    "\n",
    "        axs[1].imshow(gt, cmap=\"gray\")\n",
    "        axs[1].set_title(\"Ground Truth\")\n",
    "\n",
    "        axs[2].imshow(pr, cmap=\"gray\")\n",
    "        axs[2].set_title(\"Prediction\")\n",
    "\n",
    "        for ax in axs:\n",
    "            ax.axis(\"off\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ML)",
   "language": "python",
   "name": "ml_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
